{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 799,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "source": [
    "#data = pd.read_csv('./output.csv')\r\n",
    "data = pd.read_csv('./output_100d_real.csv')\r\n",
    "\r\n",
    "column_names = ['label','frequency_in_doc','sentence_loc', 'sentence_num']\r\n",
    "\r\n",
    "for i in range(36):\r\n",
    "    column_names.append('dep_'+str(i))\r\n",
    "for i in range(15):\r\n",
    "    column_names.append('head_pos_'+str(i))\r\n",
    "for i in range(36):\r\n",
    "    column_names.append('head_dep_'+str(i))\r\n",
    "for i in range(8):\r\n",
    "    column_names.append('entity_label_'+str(i))\r\n",
    "\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('text_'+str(i))\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('head_text_'+str(i))\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('next_verb_'+str(i))\r\n",
    "#data.columns = column_names\r\n",
    "\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('two_prior_'+str(i))\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('one_prior_'+str(i))\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('one_post_'+str(i))\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('two_post_'+str(i))\r\n",
    "\r\n",
    "data.columns = column_names\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "source": [
    "percent_no_loc = data[data['label'] != 'none'].shape[0] \r\n",
    "print('number of sentences with no location:', percent_no_loc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of sentences with no location: 2183\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "source": [
    "data_labeled = data[data['label'] != 'none']\r\n",
    "data_unlabeled = data[data['label'] == 'none']\r\n",
    "print(data_unlabeled.shape)\r\n",
    "print(data_labeled.shape)\r\n",
    "balanced_data = data_labeled.append(data_unlabeled.sample(n=data_labeled.shape[0], random_state=1))\r\n",
    "print(balanced_data.shape)\r\n",
    "data = balanced_data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(6297, 799)\n",
      "(2183, 799)\n",
      "(4366, 799)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "source": [
    "data['label'] = data['label'].astype('category')\r\n",
    "categories = dict(enumerate(data['label'].cat.categories))\r\n",
    "data['label'] = data['label'].cat.codes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "source": [
    "#dim reduce word embedding vectors - Doesn't work well\r\n",
    "# text_cols = data.iloc[:,9:309]\r\n",
    "# head_text_cols = data.iloc[:,309:609]\r\n",
    "# next_verb_cols = data.iloc[:,609:909]\r\n",
    "# prior_one_cols = data.iloc[:,909:1209]\r\n",
    "# prior_two_cols = data.iloc[:,1209:1509]\r\n",
    "# post_one_cols = data.iloc[:,1509:1809]\r\n",
    "# post_two_cols = data.iloc[:,1809:2109]\r\n",
    "\r\n",
    "# pca = PCA(n_components=100)\r\n",
    "# text_cols_reduced = pca.fit_transform(text_cols)\r\n",
    "# text_cols_reduced_df = pd.DataFrame(data=text_cols_reduced, columns=column_names[9:109])\r\n",
    "# head_text_cols_reduced = pca.fit_transform(head_text_cols)\r\n",
    "# head_text_cols_reduced_df = pd.DataFrame(data=head_text_cols_reduced, columns=column_names[309:409])\r\n",
    "# next_verb_cols_reduced = pca.fit_transform(next_verb_cols)\r\n",
    "# next_verb_cols_reduced_df = pd.DataFrame(data=next_verb_cols_reduced, columns=column_names[609:709])\r\n",
    "\r\n",
    "# prior_one_cols_reduced = pca.fit_transform(prior_one_cols)\r\n",
    "# prior_one_cols_reduced_df = pd.DataFrame(data=prior_one_cols_reduced, columns=column_names[909:1009])\r\n",
    "# prior_two_cols_reduced = pca.fit_transform(prior_two_cols)\r\n",
    "# prior_two_cols_reduced_df = pd.DataFrame(data=prior_two_cols_reduced, columns=column_names[1209:1309])\r\n",
    "# post_one_cols_reduced = pca.fit_transform(post_one_cols)\r\n",
    "# post_one_cols_reduced_df = pd.DataFrame(data=post_one_cols_reduced, columns=column_names[1509:1609])\r\n",
    "# post_two_cols_reduced = pca.fit_transform(post_two_cols)\r\n",
    "# post_two_cols_reduced_df = pd.DataFrame(data=post_two_cols_reduced, columns=column_names[1809:1909])\r\n",
    "\r\n",
    "# data = data.iloc[:,:9]\r\n",
    "# data = data.merge(text_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "# data = data.merge(head_text_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "# data = data.merge(next_verb_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "# data = data.merge(prior_one_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "# data = data.merge(prior_two_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "# data = data.merge(post_one_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "# data = data.merge(post_two_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "\r\n",
    "# print(data.shape)\r\n",
    "\r\n",
    "# print(np.any(np.isnan(data.iloc[:,9:309].to_numpy())))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "source": [
    "X = data.drop('label', axis=1)\r\n",
    "y = data['label']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "source": [
    "learning_rates = [0.05, 0.1, 0.15, 0.2]\r\n",
    "n_estimators = [50, 75, 100, 125]\r\n",
    "max_features = ['10', 'sqrt', '50', '100']\r\n",
    "max_depth = [2, 4, 6, 8]\r\n",
    "min_samples_split= [150, 200, 250]\r\n",
    "min_samples_leaf = [1]\r\n",
    "\r\n",
    "classifier = GradientBoostingClassifier(learning_rate=0.06, n_estimators=120, max_depth=4, max_features='sqrt', random_state=0, min_samples_split=50, min_samples_leaf=1)\r\n",
    "classifier.fit(X_train, y_train)\r\n",
    "y_pred = classifier.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "source": [
    "print(categories) \r\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: 'acqbus', 1: 'acqloc', 2: 'acquired', 3: 'drlamt', 4: 'none', 5: 'purchaser', 6: 'seller', 7: 'status'}\n",
      "Accuracy: 0.825091575091575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82        41\n",
      "           1       0.77      0.52      0.62        44\n",
      "           2       0.73      0.72      0.73       141\n",
      "           3       0.93      0.89      0.91        62\n",
      "           4       0.88      0.96      0.92       542\n",
      "           5       0.63      0.71      0.67       132\n",
      "           6       0.36      0.09      0.15        53\n",
      "           7       0.99      0.86      0.92        77\n",
      "\n",
      "    accuracy                           0.83      1092\n",
      "   macro avg       0.76      0.70      0.72      1092\n",
      "weighted avg       0.81      0.83      0.81      1092\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "source": [
    "filename = 'model_1.sav'\r\n",
    "pickle.dump(classifier, open(filename, 'wb'))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('venv')"
  },
  "interpreter": {
   "hash": "188ff7c4423a77199b5e01c00d13e83ee428b29f1e10ce70e71a007a382c54c3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}