{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import sklearn\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.decomposition import PCA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "#data = pd.read_csv('./output.csv')\r\n",
    "data = pd.read_csv('./output_sliding_window_100d.csv')\r\n",
    "\r\n",
    "column_names = ['label','dep','pos','head_pos','head_dep','entity_label','frequency_in_doc','sentence_loc','sentence_num']\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('text_'+str(i))\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('head_text_'+str(i))\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('next_verb_'+str(i))\r\n",
    "#data.columns = column_names\r\n",
    "\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('two_prior_'+str(i))\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('one_prior_'+str(i))\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('one_post_'+str(i))\r\n",
    "for i in range(100):\r\n",
    "    column_names.append('two_post_'+str(i))\r\n",
    "\r\n",
    "data.columns = column_names\r\n",
    "#data = data.drop(data.iloc[:,9:159], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "percent_no_loc = data[data['label'] != 'none'].shape[0] \r\n",
    "print('Percentage of sentences with no location:', percent_no_loc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percentage of sentences with no location: 1488\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "data_labeled = data[data['label'] != 'none']\r\n",
    "data_unlabeled = data[data['label'] == 'none']\r\n",
    "print(data_unlabeled.shape)\r\n",
    "print(data_labeled.shape)\r\n",
    "balanced_data = data_labeled.append(data_unlabeled.sample(n=data_labeled.shape[0]))\r\n",
    "print(balanced_data.shape)\r\n",
    "data = balanced_data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3345, 359)\n",
      "(1488, 359)\n",
      "(2976, 359)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "data_labeled = data[data['label'] != 'none']\r\n",
    "data_unlabeled = data[data['label'] == 'none']\r\n",
    "print(data_unlabeled.shape)\r\n",
    "print(data_labeled.shape)\r\n",
    "balanced_data = data_labeled.append(data_unlabeled.sample(n=data_labeled.shape[0]))\r\n",
    "print(balanced_data.shape)\r\n",
    "data = balanced_data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1488, 359)\n",
      "(1488, 359)\n",
      "(2976, 359)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "data['label'] = data['label'].astype('category')\r\n",
    "categories = dict(enumerate(data['label'].cat.categories))\r\n",
    "data['label'] = data['label'].cat.codes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "#dim reduce word embedding vectors - Doesn't work well\r\n",
    "# text_cols = data.iloc[:,9:309]\r\n",
    "# head_text_cols = data.iloc[:,309:609]\r\n",
    "# next_verb_cols = data.iloc[:,609:909]\r\n",
    "# prior_one_cols = data.iloc[:,909:1209]\r\n",
    "# prior_two_cols = data.iloc[:,1209:1509]\r\n",
    "# post_one_cols = data.iloc[:,1509:1809]\r\n",
    "# post_two_cols = data.iloc[:,1809:2109]\r\n",
    "\r\n",
    "# pca = PCA(n_components=100)\r\n",
    "# text_cols_reduced = pca.fit_transform(text_cols)\r\n",
    "# text_cols_reduced_df = pd.DataFrame(data=text_cols_reduced, columns=column_names[9:109])\r\n",
    "# head_text_cols_reduced = pca.fit_transform(head_text_cols)\r\n",
    "# head_text_cols_reduced_df = pd.DataFrame(data=head_text_cols_reduced, columns=column_names[309:409])\r\n",
    "# next_verb_cols_reduced = pca.fit_transform(next_verb_cols)\r\n",
    "# next_verb_cols_reduced_df = pd.DataFrame(data=next_verb_cols_reduced, columns=column_names[609:709])\r\n",
    "\r\n",
    "# prior_one_cols_reduced = pca.fit_transform(prior_one_cols)\r\n",
    "# prior_one_cols_reduced_df = pd.DataFrame(data=prior_one_cols_reduced, columns=column_names[909:1009])\r\n",
    "# prior_two_cols_reduced = pca.fit_transform(prior_two_cols)\r\n",
    "# prior_two_cols_reduced_df = pd.DataFrame(data=prior_two_cols_reduced, columns=column_names[1209:1309])\r\n",
    "# post_one_cols_reduced = pca.fit_transform(post_one_cols)\r\n",
    "# post_one_cols_reduced_df = pd.DataFrame(data=post_one_cols_reduced, columns=column_names[1509:1609])\r\n",
    "# post_two_cols_reduced = pca.fit_transform(post_two_cols)\r\n",
    "# post_two_cols_reduced_df = pd.DataFrame(data=post_two_cols_reduced, columns=column_names[1809:1909])\r\n",
    "\r\n",
    "# data = data.iloc[:,:9]\r\n",
    "# data = data.merge(text_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "# data = data.merge(head_text_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "# data = data.merge(next_verb_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "# data = data.merge(prior_one_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "# data = data.merge(prior_two_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "# data = data.merge(post_one_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "# data = data.merge(post_two_cols_reduced_df, left_index=True, right_index=True)\r\n",
    "\r\n",
    "# print(data.shape)\r\n",
    "\r\n",
    "# print(np.any(np.isnan(data.iloc[:,9:309].to_numpy())))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "#One hot encode categorical labels (dependency and pos features)\r\n",
    "dep_one_hot = pd.get_dummies(data['dep'], prefix='dep')\r\n",
    "pos_one_hot = pd.get_dummies(data['pos'], prefix='pos')\r\n",
    "head_pos_one_hot = pd.get_dummies(data['head_pos'], prefix='head_pos')\r\n",
    "head_dep_one_hot = pd.get_dummies(data['head_dep'], prefix='head_dep')\r\n",
    "entity_label_one_hot = pd.get_dummies(data['entity_label'], prefix='entity_label')\r\n",
    "\r\n",
    "data = data.drop(['dep', 'pos','head_pos', 'head_dep',  'entity_label'], axis=1)\r\n",
    "data = data.join(dep_one_hot)\r\n",
    "data = data.join(pos_one_hot)\r\n",
    "data = data.join(head_pos_one_hot)\r\n",
    "data = data.join(head_dep_one_hot)\r\n",
    "data = data.join(entity_label_one_hot)\r\n",
    "\r\n",
    "print(data.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2976, 446)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "X = data.drop('label', axis=1)\r\n",
    "y = data['label']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "learning_rates = [0.05, 0.1, 0.15, 0.2]\r\n",
    "n_estimators = [50, 75, 100, 125]\r\n",
    "max_features = ['10', 'sqrt', '50', '100']\r\n",
    "max_depth = [2, 4, 6, 8]\r\n",
    "min_samples_split= [150, 200, 250]\r\n",
    "min_samples_leaf = [1]\r\n",
    "\r\n",
    "classifier = GradientBoostingClassifier(learning_rate=0.06, n_estimators=120, max_depth=4,  max_features='sqrt', random_state=0, min_samples_split=50, min_samples_leaf=1)\r\n",
    "#classifier = RandomForestClassifier(random_state=0)\r\n",
    "classifier.fit(X_train, y_train)\r\n",
    "y_pred = classifier.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "source": [
    "print(categories) \r\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: 'acqbus', 1: 'acqloc', 2: 'acquired', 3: 'drlamt', 4: 'none', 5: 'purchaser', 6: 'seller', 7: 'status'}\n",
      "Accuracy: 0.8051075268817204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.48      0.58        23\n",
      "           1       0.68      0.45      0.54        29\n",
      "           2       0.63      0.63      0.63        91\n",
      "           3       1.00      0.65      0.79        40\n",
      "           4       0.88      0.98      0.92       367\n",
      "           5       0.62      0.78      0.69        96\n",
      "           6       0.50      0.15      0.23        33\n",
      "           7       0.98      0.83      0.90        65\n",
      "\n",
      "    accuracy                           0.81       744\n",
      "   macro avg       0.75      0.62      0.66       744\n",
      "weighted avg       0.80      0.81      0.79       744\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('venv')"
  },
  "interpreter": {
   "hash": "188ff7c4423a77199b5e01c00d13e83ee428b29f1e10ce70e71a007a382c54c3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}